# -*- coding: utf-8 -*-
"""A4_submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X8niOm5T7CnlJPvsqZuOiq06CgibHS1Q
"""

-*- coding: utf-8 -*-
"""A4_submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GmbuVx5thKbeLoy1OUAHyZYNzuxap6iI
"""

import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torch.optim as optim
from scipy import ndimage

import torch
import torchvision
from torchvision import transforms as T
import torch.nn.functional as F

import torchvision.models.detection as models

import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
# from ultralytics import YOLO
from scipy.ndimage.measurements import label, find_objects

# check point
# run inferences

# recource: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/image_segmentation/semantic_segmentation_unet/train.py


class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.conv(x)

class UNET(nn.Module):
    def __init__(self, in_channels=3, out_channels=11, features=[64, 128, 256, 512],):
        super(UNET, self).__init__()
        self.ups = nn.ModuleList()
        self.downs = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Down
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature

        # Up
        for feature in reversed(features):
            self.ups.append(
                nn.ConvTranspose2d(
                    feature*2, feature, kernel_size=2, stride=2,
                )
            )
            # After we go up, then we go through two convolutional neural network
            self.ups.append(DoubleConv(feature*2, feature))

        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []

        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)

        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]

        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]

            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])

            concat_skip = torch.cat((skip_connection, x), dim=1)
            x = self.ups[idx+1](concat_skip)

        return self.final_conv(x)

class CustomDataset(Dataset):
    def __init__(self, image, transform=None):
        self.images = image
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        image = self.images[index].reshape(64, 64, 3).astype(np.float32)
        # image = (image - image.min()) / (image.max() - image.min())

        # if self.transform is not None:
        #     sample = self.transform(image)

        if self.transform is not None:
            augmented = self.transform(image=image)
            image = augmented["image"]

        return image

def get_loaders( images, batch_size, val_transform, num_workers=2,pin_memory=True,):
    val_ds = CustomDataset(
        images,
        transform = val_transform,
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=batch_size,
        num_workers=num_workers,
        pin_memory=pin_memory,
        shuffle=False,
    )
    return val_loader

def detect_and_segment(images):

    """

    :param np.ndarray images: N x 12288 array containing N 64x64x3 images flattened into vectors
    :return: np.ndarray, np.ndarray
    """

    N = images.shape[0]

    # pred_class: Your predicted labels for the 2 digits, shape [N, 2]
    pred_class = np.empty((N, 2), dtype=np.int32)

    # pred_bboxes: Your predicted bboxes for 2 digits, shape [N, 2, 4]
    pred_bboxes = np.empty((N, 2, 4), dtype=np.float64)

    # pred_seg: Your predicted segmentation for the image, shape [N, 4096]
    pred_seg = np.empty((N, 4096), dtype=np.int32)

    # classification & detection (yolo)
    # model_classification = YOLO("best4.pt")

    # valid_output_directory = "./classification"
    # os.makedirs(valid_output_directory, exist_ok=True)


    # for i, image in enumerate(images):  # images: ( )
    #     image = image.reshape(64, 64, 3)
    #     # Convert NumPy array to PIL Image
    #     pil_image = Image.fromarray(image)

    #     # Save the image as a PNG file
    #     image_filename = os.path.join(valid_output_directory, f"{i}.png")
    #     pil_image.save(image_filename, "PNG")
    #     # img = cv2.imread(image_filename)
    #     results = model_classification(image_filename)
    #     for result in results:
    #         boxes = result.boxes.cpu().numpy()  # Boxes object for bbox outputs
    #         xyxys = boxes.xyxy
    #         print(xyxys.shape)
    #         pred_bboxes[i] = xyxys


    # -------------------------yolo ends--------------------------------

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


    model = UNET(in_channels=3, out_channels=11)
    # optimizer = optim.Adam(model.parameters(), lr=5e-4)
    model.load_state_dict(torch.load("my_checkpoint.pth.tar")["state_dict"])
    # optimizer.load_state_dict(torch.load("my_checkpoint.pth.tar",map_location='cpu')['optimizer'])

    model.to(device)
    model.eval()

    batch_size = 20  # 15 good

    val_transform = A.Compose(
        [
            A.Resize(height=64, width=64),
            A.Normalize(
                mean=[0.0, 0.0, 0.0],
                std=[1.0, 1.0, 1.0],
                max_pixel_value=255.0,
            ),
            ToTensorV2(),
        ],
    )

    val_loader = get_loaders(images,batch_size,val_transform)

    predicted_masks = []
    predictions = None

    with torch.no_grad():  # Disable gradient computation during evaluation
        for batch, sample in enumerate(val_loader):
            images = sample.to(device)  # Move the data to the device torch.Size([15, 3, 64, 64])

            predictions = model(images) # ( 20, 11, 64,64)
            predictions_classes = torch.argmax(predictions, dim =1) # ( 20, 64,64)

            for i in range(predictions_classes.shape[0]):
                 predicted_masks.append(predictions_classes[i].cpu().numpy()) # tensor
    predicted_masks = np.array(predicted_masks).astype(np.int32)
    pred_seg = np.reshape(predicted_masks,(N,4096))

    # classification
    for i in range(N):
        image_mask = pred_seg[i]

        image_mask = image_mask.flatten()  # 4096
        unique_values, counts = np.unique(image_mask, return_counts=True)  # [4,6,8,10]  [1,34,55,100]
        sorted_indices = np.argsort(counts)[::-1] # [3,2,1,0]
        unique_values_sorted = [unique_values[index] for index in sorted_indices]
        unique_values_sorted = unique_values_sorted[1:]
        if len(unique_values_sorted)== 1:
            unique_values_sorted =unique_values_sorted + [unique_values_sorted[0]]
            # print(unique_values_sorted)

        elif len(unique_values_sorted) >= 2: # more than one unqiue (different digits)
            if unique_values_sorted[0]> unique_values_sorted[1]: # [ 7,5 ]
                unique_values_sorted = [unique_values_sorted[1],unique_values_sorted[0]]  # [ 5,7]
            else:
                # unique_values_sorted = [unique_values_sorted[0],unique_values_sorted[1]]
                unique_values_sorted =unique_values_sorted[:2]

        pred_class[i]=np.array(unique_values_sorted).reshape(1,2)  # (3,5)

        mask = pred_seg.reshape(N, 64, 64)[i]   # (64,64)  0-9
        boxes = []
        if pred_class[i][0]!= pred_class[i][1]:  #2 different  digits
            binary_mask1 = (mask == pred_class[i][0]).astype(np.uint8)
            binary_mask2 = (mask == pred_class[i][1]).astype(np.uint8)

            center1 = ndimage.center_of_mass(binary_mask1)
            center1_y, center1_x = center1  # row, col
            y_min = center1_y-14
            y_max = center1_y+14
            x_min = center1_x-14
            x_max = center1_x+14
            box1 = [y_min,x_min,y_max,x_max]

            center2 = ndimage.center_of_mass(binary_mask2)
            center2_y, center2_x = center2  # row, col
            y_min = center2_y-14
            y_max = center2_y+14
            x_min = center2_x-14
            x_max = center2_x+14
            box2 = [y_min,x_min,y_max,x_max]

            pred_bboxes[i] = [box1, box2]
        else:
            labeled_mask, num_features = label(mask != 10)

            if num_features>2:
                num_features=2

            binary_mask1 = (labeled_mask == 1).astype(np.uint8)
            binary_mask2 = (labeled_mask == 2).astype(np.uint8)

            center1 = ndimage.center_of_mass(binary_mask1)
            center1_y, center1_x = center1  # row, col
            y_min = center1_y-14
            y_max = center1_y+14
            x_min = center1_x-14
            x_max = center1_x+14
            box1 = [y_min,x_min,y_max,x_max]

            center2 = ndimage.center_of_mass(binary_mask2)
            center2_y, center2_x = center2  # row, col
            y_min = center2_y-14
            y_max = center2_y+14
            x_min = center2_x-14
            x_max = center2_x+14
            box2 = [y_min,x_min,y_max,x_max]

            pred_bboxes[i] = [box1, box2]


    return pred_class, pred_bboxes, pred_seg